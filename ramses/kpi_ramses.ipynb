{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kpi.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"./models/ramses_kpi/tmp/checkpoint\"\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               20992     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 30,028\n",
      "Trainable params: 30,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None \n",
      "\n",
      "Epoch 1/200\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 1.9192 - accuracy: 0.3200\n",
      "Epoch 00001: loss improved from inf to 1.88525, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 1.8852 - accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 1.0985 - accuracy: 0.6603\n",
      "Epoch 00002: loss improved from 1.88525 to 1.09948, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 1.0995 - accuracy: 0.6588\n",
      "Epoch 3/200\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.6321 - accuracy: 0.8182\n",
      "Epoch 00003: loss improved from 1.09948 to 0.63549, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6355 - accuracy: 0.8185\n",
      "Epoch 4/200\n",
      "119/128 [==========================>...] - ETA: 0s - loss: 0.5041 - accuracy: 0.8538\n",
      "Epoch 00004: loss improved from 0.63549 to 0.50788, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.5079 - accuracy: 0.8529\n",
      "Epoch 5/200\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.4052 - accuracy: 0.8816\n",
      "Epoch 00005: loss improved from 0.50788 to 0.40918, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4092 - accuracy: 0.8795\n",
      "Epoch 6/200\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.3611 - accuracy: 0.8869\n",
      "Epoch 00006: loss improved from 0.40918 to 0.35541, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3554 - accuracy: 0.8889\n",
      "Epoch 7/200\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8873\n",
      "Epoch 00007: loss improved from 0.35541 to 0.34263, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3426 - accuracy: 0.8873\n",
      "Epoch 8/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8952\n",
      "Epoch 00008: loss improved from 0.34263 to 0.31769, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3177 - accuracy: 0.8951\n",
      "Epoch 9/200\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.2906 - accuracy: 0.9008\n",
      "Epoch 00009: loss improved from 0.31769 to 0.29789, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2979 - accuracy: 0.8998\n",
      "Epoch 10/200\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.2669 - accuracy: 0.9124\n",
      "Epoch 00010: loss improved from 0.29789 to 0.25866, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.2587 - accuracy: 0.9155\n",
      "Epoch 11/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.2527 - accuracy: 0.9127\n",
      "Epoch 00011: loss did not improve from 0.25866\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2589 - accuracy: 0.9108\n",
      "Epoch 12/200\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9264 ETA: 0s - los\n",
      "Epoch 00012: loss improved from 0.25866 to 0.23184, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2318 - accuracy: 0.9264\n",
      "Epoch 13/200\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.9343\n",
      "Epoch 00013: loss improved from 0.23184 to 0.22066, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2207 - accuracy: 0.9343\n",
      "Epoch 14/200\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9403\n",
      "Epoch 00014: loss improved from 0.22066 to 0.20215, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2022 - accuracy: 0.9405\n",
      "Epoch 15/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9444\n",
      "Epoch 00015: loss improved from 0.20215 to 0.18428, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.1843 - accuracy: 0.9452\n",
      "Epoch 16/200\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.1593 - accuracy: 0.9492\n",
      "Epoch 00016: loss improved from 0.18428 to 0.15454, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.1545 - accuracy: 0.9515\n",
      "Epoch 17/200\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9499\n",
      "Epoch 00017: loss improved from 0.15454 to 0.15199, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.1520 - accuracy: 0.9499\n",
      "Epoch 18/200\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.1372 - accuracy: 0.9623\n",
      "Epoch 00018: loss improved from 0.15199 to 0.13572, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.1357 - accuracy: 0.9624\n",
      "Epoch 19/200\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.9606\n",
      "Epoch 00019: loss did not improve from 0.13572\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.9609\n",
      "Epoch 20/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9762\n",
      "Epoch 00020: loss improved from 0.13572 to 0.09826, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0983 - accuracy: 0.9750\n",
      "Epoch 21/200\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 0.1068 - accuracy: 0.9667\n",
      "Epoch 00021: loss did not improve from 0.09826\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9656\n",
      "Epoch 22/200\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.1016 - accuracy: 0.9705\n",
      "Epoch 00022: loss did not improve from 0.09826\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.1052 - accuracy: 0.9687\n",
      "Epoch 23/200\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.1023 - accuracy: 0.9691\n",
      "Epoch 00023: loss did not improve from 0.09826\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.1027 - accuracy: 0.9687\n",
      "Epoch 24/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9667\n",
      "Epoch 00024: loss did not improve from 0.09826\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.1008 - accuracy: 0.9671\n",
      "Epoch 25/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9841\n",
      "Epoch 00025: loss improved from 0.09826 to 0.07276, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9812\n",
      "Epoch 26/200\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.0655 - accuracy: 0.9805\n",
      "Epoch 00026: loss improved from 0.07276 to 0.07215, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.0721 - accuracy: 0.9781\n",
      "Epoch 27/200\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9778\n",
      "Epoch 00027: loss improved from 0.07215 to 0.06833, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0683 - accuracy: 0.9781\n",
      "Epoch 28/200\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.0678 - accuracy: 0.9738\n",
      "Epoch 00028: loss did not improve from 0.06833\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0714 - accuracy: 0.9718\n",
      "Epoch 29/200\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.0692 - accuracy: 0.9772\n",
      "Epoch 00029: loss improved from 0.06833 to 0.06736, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9781\n",
      "Epoch 30/200\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.0416 - accuracy: 0.9919\n",
      "Epoch 00030: loss improved from 0.06736 to 0.04035, saving model to ./models/ramses_kpi/tmp/checkpoint\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9922\n",
      "Epoch 31/200\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9906\n",
      "Epoch 00031: loss did not improve from 0.04035\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.0514 - accuracy: 0.9906\n",
      "Epoch 32/200\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9888\n",
      "Epoch 00032: loss did not improve from 0.04035\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.0433 - accuracy: 0.9890\n",
      "Epoch 33/200\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9887\n",
      "Epoch 00033: loss did not improve from 0.04035\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.0487 - accuracy: 0.9890\n",
      "Epoch 34/200\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9774\n",
      "Epoch 00034: loss did not improve from 0.04035\n",
      "128/128 [==============================] - 2s 12ms/step - loss: 0.0685 - accuracy: 0.9781\n",
      "Epoch 35/200\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.0479 - accuracy: 0.9869\n",
      "Epoch 00035: loss did not improve from 0.04035\n",
      "128/128 [==============================] - 2s 14ms/step - loss: 0.0493 - accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = [\"'s\"]\n",
    "ignore_words.extend(string.punctuation)\n",
    "\n",
    "try:\n",
    "    with open('data.pickle', 'rb') as file:\n",
    "        words, classes, documents = pickle.load(file)\n",
    "except:\n",
    "    # loop through each sentence in our intents pattern\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            # tokenize each word in the sentence\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds) # add to word list\n",
    "            documents.append((wrds, intent['tag'])) # add to documents in our corpus\n",
    "\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag']) # add to our class list\n",
    "\n",
    "    # stem and lower each word and remove duplicates\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    classes = sorted(list(set(classes))) # sort classes\n",
    "\n",
    "    print(f\"{len(documents)} documents\\n{len(classes)} classes\\n{len(words)} unique stemmed words\")\n",
    "\n",
    "#     with open('data.pickle', 'wb') as file:\n",
    "#         pickle.dump((words, classes, documents), file)\n",
    "\n",
    "\n",
    "# create our training data\n",
    "training = []\n",
    "output_empty = [0 for _ in range(len(classes))]\n",
    "\n",
    "for doc in documents: # bag of words\n",
    "    bag = []\n",
    "    s_words = [stemmer.stem(w.lower()) for w in doc[0] if w not in ignore_words]\n",
    "    \n",
    "    for w in words:\n",
    "        bag.append(1) if w in s_words else bag.append(0)\n",
    "        \n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "    \n",
    "# shuffle our features and turn intp np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test list.\n",
    "train_x = list(training[:, 0])\n",
    "train_y = list(training[:, 1])\n",
    "\n",
    "print(f\"{train_x.shape} {train_y.shape}\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# print(\"\\n\",model.summary(), \"\\n\")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1, callbacks=my_callbacks)\n",
    "model.load_weights(\"./models/ramses_kpi/tmp/checkpoint\")\n",
    "model.save(\"./models/ramses_kpi/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-2a28e402268c>\", line 42, in <module>\n",
      "    inp = input(\"You: \")\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 860, in raw_input\n",
      "    return self._input_request(str(prompt),\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 904, in _input_request\n",
      "    raise KeyboardInterrupt(\"Interrupted by user\") from None\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-2a28e402268c>\", line 42, in <module>\n",
      "    inp = input(\"You: \")\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 860, in raw_input\n",
      "    return self._input_request(str(prompt),\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 904, in _input_request\n",
      "    raise KeyboardInterrupt(\"Interrupted by user\") from None\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2046, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1335, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 362, in _fixed_getinnerframes\n",
      "    aux = traceback.extract_tb(etb)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/traceback.py\", line 72, in extract_tb\n",
      "    return StackSummary.extract(walk_tb(tb), limit=limit)\n",
      "  File \"/home/vegas/anaconda3/envs/deeplearning/lib/python3.8/traceback.py\", line 336, in extract\n",
      "    limit = getattr(sys, 'tracebacklimit', None)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2a28e402268c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3262\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures)\u001b[0m\n\u001b[1;32m   3069\u001b[0m                     \u001b[0minteractivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'async'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0m\u001b[1;32m   3072\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0mchained_exc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0m\u001b[1;32m   1211\u001b[0m                                                                      chained_exceptions_tb_offset)\n\u001b[1;32m   1212\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    s_words = nltk.word_tokenize(sentence)\n",
    "    s_words = [stemmer.stem(w.lower()) for w in s_words if w not in ignore_words]\n",
    "    \n",
    "    return s_words\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    s_words = clean_up_sentence(sentence)\n",
    "    \n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    \n",
    "    for s in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                \n",
    "                if show_details:\n",
    "                    print(f\"found in bag: {s}\")\n",
    "                    \n",
    "    return np.array(bag)\n",
    "\n",
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    input_data = pd.DataFrame([bow(sentence, words, show_details=False)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    \n",
    "    #filter out prediction below a threshold, and provide intent index\n",
    "    results = [[i, r] for i, r in enumerate(results) if r > ERROR_THRESHOLD]\n",
    "    \n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "    \n",
    "    print(f\"\\n{return_list}\")\n",
    "    return return_list\n",
    "    \n",
    "while True:\n",
    "    inp = input(\"You: \")\n",
    "    \n",
    "    if inp == 'quit' or inp == 'stop' or inp == 'q':\n",
    "        break\n",
    "        \n",
    "    results = classify_local(inp)[0]\n",
    "    \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == results[0]:\n",
    "            responses = intent['responses']\n",
    "    \n",
    "    print(\"\\n\", random.choice(responses), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = load_model(filepath)\n",
    "# inp = input(\"You: \")\n",
    "# input_data = pd.DataFrame([bow(inp, words, show_details=False)], dtype=float, index=['input'])\n",
    "# assert_allclose(model.predict(input_data), new_model.predict(input_data), 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloaded_obj = load_model(\"models/ramses_kpi/model.h5\")\n",
    "# reloaded_obj.load_weights(\"./models/ramses_kpi/tmp/checkpoint\")\n",
    "# reloaded_obj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"./models/ramses_kpi/model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.normpath(filename + os.sep + os.pardir) + \"/tmp/checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
