{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, Bidirectional, Reshape\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kpi_identifier.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"tmp/checkpoint\"\n",
    "\n",
    "my_callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10),\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.01, patience=10, min_lr=0.001, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 documents\n",
      "12 classes\n",
      "163 unique stemmed words\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = [\"'s\"]\n",
    "ignore_words.extend(string.punctuation)\n",
    "\n",
    "# try:\n",
    "#     with open('data.pickle', 'rb') as file:\n",
    "#         words, classes, documents = pickle.load(file)\n",
    "# except:\n",
    "# loop through each sentence in our intents pattern\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        wrds = nltk.word_tokenize(pattern)\n",
    "        words.extend(wrds) # add to word list\n",
    "        documents.append((wrds, intent['tag'])) # add to documents in our corpus\n",
    "\n",
    "    if intent['tag'] not in classes:\n",
    "        classes.append(intent['tag']) # add to our class list\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "classes = sorted(list(set(classes))) # sort classes\n",
    "\n",
    "print(f\"{len(documents)} documents\\n{len(classes)} classes\\n{len(words)} unique stemmed words\")\n",
    "\n",
    "with open('data.pickle', 'wb') as file:\n",
    "    pickle.dump((words, classes, documents), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 1, 163) (639, 12)\n",
      "\n",
      "============================= Create a new model =============================\n",
      "\n",
      "Epoch 1/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 2.0923 - accuracy: 0.2476\n",
      "Epoch 00001: loss improved from inf to 2.09263, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 2.0926 - accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 1.9128 - accuracy: 0.2796\n",
      "Epoch 00002: loss improved from 2.09263 to 1.91078, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 1.9108 - accuracy: 0.2817 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 1.7873 - accuracy: 0.3621\n",
      "Epoch 00003: loss improved from 1.91078 to 1.78554, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 9ms/step - loss: 1.7855 - accuracy: 0.3631 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 1.5495 - accuracy: 0.4977\n",
      "Epoch 00004: loss improved from 1.78554 to 1.54950, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 1.5495 - accuracy: 0.4977 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 1.1746 - accuracy: 0.6609\n",
      "Epoch 00005: loss improved from 1.54950 to 1.17745, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 1.1775 - accuracy: 0.6604 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.8977 - accuracy: 0.7586\n",
      "Epoch 00006: loss improved from 1.17745 to 0.89645, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.8965 - accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.7953\n",
      "Epoch 00007: loss improved from 0.89645 to 0.69741, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.6974 - accuracy: 0.7966 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.8414\n",
      "Epoch 00008: loss improved from 0.69741 to 0.58741, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.5874 - accuracy: 0.8419 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.8457\n",
      "Epoch 00009: loss improved from 0.58741 to 0.52386, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.5239 - accuracy: 0.8466 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.8560\n",
      "Epoch 00010: loss improved from 0.52386 to 0.46774, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.4677 - accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.8861\n",
      "Epoch 00011: loss improved from 0.46774 to 0.40412, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.4041 - accuracy: 0.8842 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.3744 - accuracy: 0.8962\n",
      "Epoch 00012: loss improved from 0.40412 to 0.37315, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.3732 - accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.9058\n",
      "Epoch 00013: loss improved from 0.37315 to 0.34252, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.3425 - accuracy: 0.9045 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "629/639 [============================>.] - ETA: 0s - loss: 0.3280 - accuracy: 0.9030\n",
      "Epoch 00014: loss improved from 0.34252 to 0.32546, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.3255 - accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.2949 - accuracy: 0.9105\n",
      "Epoch 00015: loss improved from 0.32546 to 0.29395, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.2939 - accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.9060\n",
      "Epoch 00016: loss improved from 0.29395 to 0.27843, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.2784 - accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9148\n",
      "Epoch 00017: loss improved from 0.27843 to 0.26402, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.2640 - accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.9114\n",
      "Epoch 00018: loss improved from 0.26402 to 0.24978, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.2498 - accuracy: 0.9124 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.9194\n",
      "Epoch 00019: loss improved from 0.24978 to 0.23795, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.2379 - accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.2291 - accuracy: 0.9214\n",
      "Epoch 00020: loss improved from 0.23795 to 0.22806, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.2281 - accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9308\n",
      "Epoch 00021: loss improved from 0.22806 to 0.20817, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.2082 - accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 0.9402\n",
      "Epoch 00022: loss improved from 0.20817 to 0.19368, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.1937 - accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9371\n",
      "Epoch 00023: loss improved from 0.19368 to 0.18965, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1897 - accuracy: 0.9358 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.9372\n",
      "Epoch 00024: loss improved from 0.18965 to 0.17344, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.1734 - accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9418\n",
      "Epoch 00025: loss improved from 0.17344 to 0.16132, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.1613 - accuracy: 0.9421 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9575\n",
      "Epoch 00026: loss improved from 0.16132 to 0.14872, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1487 - accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.9545\n",
      "Epoch 00027: loss improved from 0.14872 to 0.13510, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1351 - accuracy: 0.9546 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9511\n",
      "Epoch 00028: loss did not improve from 0.13510\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1414 - accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9589\n",
      "Epoch 00029: loss improved from 0.13510 to 0.13137, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1314 - accuracy: 0.9593 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9575\n",
      "Epoch 00030: loss improved from 0.13137 to 0.12408, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1241 - accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9778\n",
      "Epoch 00031: loss improved from 0.12408 to 0.09666, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0967 - accuracy: 0.9781 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0885 - accuracy: 0.9795\n",
      "Epoch 00032: loss improved from 0.09666 to 0.08782, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0878 - accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9826\n",
      "Epoch 00033: loss improved from 0.08782 to 0.08315, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0831 - accuracy: 0.9828 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9655\n",
      "Epoch 00034: loss did not improve from 0.08315\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.1015 - accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9810\n",
      "Epoch 00035: loss improved from 0.08315 to 0.07653, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0765 - accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9827\n",
      "Epoch 00036: loss did not improve from 0.07653\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0789 - accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9812\n",
      "Epoch 00037: loss improved from 0.07653 to 0.07031, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0703 - accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9922\n",
      "Epoch 00038: loss improved from 0.07031 to 0.05563, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0556 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9843\n",
      "Epoch 00039: loss did not improve from 0.05563\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0647 - accuracy: 0.9844 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9906\n",
      "Epoch 00040: loss improved from 0.05563 to 0.05511, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0551 - accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9937\n",
      "Epoch 00041: loss improved from 0.05511 to 0.04999, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0500 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9811\n",
      "Epoch 00042: loss did not improve from 0.04999\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0598 - accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9890\n",
      "Epoch 00043: loss improved from 0.04999 to 0.04957, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0496 - accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9921\n",
      "Epoch 00044: loss improved from 0.04957 to 0.03387, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0339 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9922\n",
      "Epoch 00045: loss did not improve from 0.03387\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0412 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9874\n",
      "Epoch 00046: loss did not improve from 0.03387\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0474 - accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9937\n",
      "Epoch 00047: loss did not improve from 0.03387\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0373 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9921\n",
      "Epoch 00048: loss did not improve from 0.03387\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0355 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9858\n",
      "Epoch 00049: loss did not improve from 0.03387\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0428 - accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9875\n",
      "Epoch 00050: loss did not improve from 0.03387\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0455 - accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9984\n",
      "Epoch 00051: loss improved from 0.03387 to 0.02747, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0275 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9906\n",
      "Epoch 00052: loss did not improve from 0.02747\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0360 - accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9953\n",
      "Epoch 00053: loss did not improve from 0.02747\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0289 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9953\n",
      "Epoch 00054: loss improved from 0.02747 to 0.02056, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0206 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9953\n",
      "Epoch 00055: loss did not improve from 0.02056\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0319 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9937\n",
      "Epoch 00056: loss did not improve from 0.02056\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0255 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 00057: loss improved from 0.02056 to 0.01769, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0177 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9953\n",
      "Epoch 00058: loss did not improve from 0.01769\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0240 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9969\n",
      "Epoch 00059: loss did not improve from 0.01769\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0223 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9921\n",
      "Epoch 00060: loss did not improve from 0.01769\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0307 - accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9984\n",
      "Epoch 00061: loss did not improve from 0.01769\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0202 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9969\n",
      "Epoch 00062: loss did not improve from 0.01769\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0195 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9969\n",
      "Epoch 00063: loss improved from 0.01769 to 0.01575, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0158 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9953\n",
      "Epoch 00064: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0184 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9921\n",
      "Epoch 00065: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0243 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9937\n",
      "Epoch 00066: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0206 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9969\n",
      "Epoch 00067: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0161 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9937\n",
      "Epoch 00068: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0234 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9937\n",
      "Epoch 00069: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0232 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9984\n",
      "Epoch 00070: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0183 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9969\n",
      "Epoch 00071: loss did not improve from 0.01575\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0207 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9984\n",
      "Epoch 00072: loss improved from 0.01575 to 0.01079, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0108 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9968\n",
      "Epoch 00073: loss did not improve from 0.01079\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0161 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9953\n",
      "Epoch 00074: loss did not improve from 0.01079\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0211 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9922\n",
      "Epoch 00075: loss did not improve from 0.01079\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0477 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9984\n",
      "Epoch 00076: loss did not improve from 0.01079\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0118 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 00077: loss did not improve from 0.01079\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0115 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 00078: loss did not improve from 0.01079\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0128 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 00079: loss improved from 0.01079 to 0.01018, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0102 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9984\n",
      "Epoch 00080: loss did not improve from 0.01018\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0166 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9968\n",
      "Epoch 00081: loss did not improve from 0.01018\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0155 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9984\n",
      "Epoch 00082: loss did not improve from 0.01018\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0173 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9984\n",
      "Epoch 00083: loss improved from 0.01018 to 0.01014, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0101 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9984\n",
      "Epoch 00084: loss improved from 0.01014 to 0.00944, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0094 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9984\n",
      "Epoch 00085: loss did not improve from 0.00944\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0104 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 00086: loss did not improve from 0.00944\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0207 - accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9984\n",
      "Epoch 00087: loss did not improve from 0.00944\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0117 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 00088: loss improved from 0.00944 to 0.00701, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9969\n",
      "Epoch 00089: loss did not improve from 0.00701\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0135 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9969\n",
      "Epoch 00090: loss did not improve from 0.00701\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0119 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9953\n",
      "Epoch 00091: loss did not improve from 0.00701\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0178 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9984\n",
      "Epoch 00092: loss did not improve from 0.00701\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0077 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9984\n",
      "Epoch 00093: loss did not improve from 0.00701\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0089 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9984\n",
      "Epoch 00094: loss did not improve from 0.00701\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0114 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9984\n",
      "Epoch 00095: loss improved from 0.00701 to 0.00653, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0065 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9953\n",
      "Epoch 00096: loss did not improve from 0.00653\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0227 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9984\n",
      "Epoch 00097: loss did not improve from 0.00653\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0115 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9969\n",
      "Epoch 00098: loss did not improve from 0.00653\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0156 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 00099: loss improved from 0.00653 to 0.00590, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9984\n",
      "Epoch 00100: loss did not improve from 0.00590\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0081 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9984\n",
      "Epoch 00101: loss did not improve from 0.00590\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0075 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00102: loss did not improve from 0.00590\n",
      "639/639 [==============================] - 5s 9ms/step - loss: 0.0094 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 00103: loss improved from 0.00590 to 0.00474, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9984\n",
      "Epoch 00104: loss did not improve from 0.00474\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0077 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9984\n",
      "Epoch 00105: loss did not improve from 0.00474\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0070 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9984\n",
      "Epoch 00106: loss did not improve from 0.00474\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0064 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 00107: loss did not improve from 0.00474\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0057 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9984\n",
      "Epoch 00108: loss did not improve from 0.00474\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0066 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00109: loss improved from 0.00474 to 0.00369, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 00110: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0084 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 00111: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9984\n",
      "Epoch 00112: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0078 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 00113: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "629/639 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00114: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 00115: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00116: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 00117: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 00118: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "630/639 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0067 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 00120: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 00121: loss did not improve from 0.00369\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00122: loss improved from 0.00369 to 0.00368, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00123: loss improved from 0.00368 to 0.00314, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00124: loss did not improve from 0.00314\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0058 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00125: loss did not improve from 0.00314\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00126: loss improved from 0.00314 to 0.00299, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00127: loss did not improve from 0.00299\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9984\n",
      "Epoch 00128: loss did not improve from 0.00299\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0071 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 00129: loss did not improve from 0.00299\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0042 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00130: loss improved from 0.00299 to 0.00267, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00131: loss did not improve from 0.00267\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 00132: loss did not improve from 0.00267\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00133: loss did not improve from 0.00267\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 00134: loss did not improve from 0.00267\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 00135: loss did not improve from 0.00267\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 00136: loss did not improve from 0.00267\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0105 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 00137: loss improved from 0.00267 to 0.00248, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9921\n",
      "Epoch 00138: loss did not improve from 0.00248\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0188 - accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00139: loss did not improve from 0.00248\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00140: loss did not improve from 0.00248\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00141: loss improved from 0.00248 to 0.00224, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 00142: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 00143: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0092 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00144: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 00145: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0098 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00146: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00147: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 00148: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0046 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9984\n",
      "Epoch 00149: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0069 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00150: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9984\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00151: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0035 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 00152: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00153: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 154/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9968\n",
      "Epoch 00154: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0068 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 155/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00155: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0052 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 156/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00156: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0059 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 157/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 00157: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0046 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 158/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00158: loss did not improve from 0.00224\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 159/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 00159: loss improved from 0.00224 to 0.00200, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 160/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00160: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0052 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 161/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 00161: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 162/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00162: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 163/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00163: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 164/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00164: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 165/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00165: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 166/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00166: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 167/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00167: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0059 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 168/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00168: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 169/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00169: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 170/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9984\n",
      "Epoch 00170: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0035 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 171/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9984\n",
      "Epoch 00171: loss did not improve from 0.00200\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 172/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00172: loss improved from 0.00200 to 0.00124, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 173/200\n",
      "637/639 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 00173: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0054 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 174/200\n",
      "629/639 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00174: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 175/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 00175: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 176/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 00176: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 177/200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 00177: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 178/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00178: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 179/200\n",
      "630/639 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9984\n",
      "Epoch 00179: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 180/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00180: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 181/200\n",
      "628/639 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00181: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0046 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 182/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9968\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00182: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0082 - accuracy: 0.9969 - lr: 0.0010\n",
      "Epoch 183/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00183: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 184/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00184: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 185/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00185: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 186/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00186: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 187/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00187: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 188/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 00188: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 189/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00189: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 190/200\n",
      "633/639 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 00190: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 191/200\n",
      "634/639 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00191: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 192/200\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00192: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 193/200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00193: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 194/200\n",
      "628/639 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 00194: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 195/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00195: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 196/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00196: loss did not improve from 0.00124\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0050 - accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 197/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00197: loss improved from 0.00124 to 0.00114, saving model to tmp/checkpoint\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 198/200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00198: loss did not improve from 0.00114\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 199/200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00199: loss did not improve from 0.00114\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 200/200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00200: loss did not improve from 0.00114\n",
      "639/639 [==============================] - 4s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f57443ec040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output_empty = [0 for _ in range(len(classes))]\n",
    "\n",
    "for doc in documents: # bag of words\n",
    "    bag = []\n",
    "    s_words = [stemmer.stem(w.lower()) for w in doc[0] if w not in ignore_words]\n",
    "    \n",
    "    for w in words:\n",
    "        bag.append(1) if w in s_words else bag.append(0)\n",
    "        \n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "    \n",
    "# shuffle our features and turn intp np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test list.\n",
    "train_x = tf.cast(np.array(list(training[:, 0])), tf.float32)\n",
    "train_y = tf.cast(np.array(list(training[:, 1])), tf.float32)\n",
    "\n",
    "train_x = tf.reshape(train_x, (train_x.shape[0], 1, train_x.shape[1]))\n",
    "print(f\"{train_x.shape} {train_y.shape}\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=train_x.shape[2], input_shape=(1, train_x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(train_y.shape[1], activation=\"softmax\"))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "if not tf.io.gfile.exists(filepath):\n",
    "    print(\"\\n============================= Create a new model =============================\\n\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "else:\n",
    "    print(\"\\n============================= Load existing model weights =============================\\n\")\n",
    "    model = tf.keras.models.load_model(\"kpi_identifier.hdf5\")\n",
    "    model.load_weights(filepath)\n",
    "    \n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=200, batch_size=1, verbose=1, callbacks=my_callbacks)\n",
    "# model.load_weights(\"./models/ramses_kpi/tmp/checkpoint\")\n",
    "# model.save(\"./models/ramses_kpi/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    s_words = nltk.word_tokenize(sentence)\n",
    "    s_words = [stemmer.stem(w.lower()) for w in s_words if w not in ignore_words]\n",
    "    \n",
    "    return s_words\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    s_words = clean_up_sentence(sentence)\n",
    "    \n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    \n",
    "    for s in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                \n",
    "                if show_details:\n",
    "                    print(f\"found in bag: {s}\")\n",
    "                    \n",
    "    return np.array(bag)\n",
    "\n",
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.6\n",
    "    \n",
    "    input_data = pd.DataFrame([bow(sentence, words, show_details=False)], dtype=float, index=['input'])\n",
    "    input_data = input_data.values.reshape(-1, 1, input_data.shape[1])\n",
    "        \n",
    "    results = model.predict([input_data])[0]\n",
    "    \n",
    "    #filter out prediction below a threshold, and provide intent index\n",
    "    results = [[i, r] for i, r in enumerate(results) if r > ERROR_THRESHOLD]\n",
    "    \n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "        \n",
    "    print(return_list)\n",
    "    return return_list\n",
    "    \n",
    "# while True:\n",
    "#     inp = input(\"You: \")\n",
    "\n",
    "#     if inp == 'quit' or inp == 'stop' or inp == 'q':\n",
    "#         break\n",
    "\n",
    "#     try:\n",
    "#         results = classify_local(inp)[0]\n",
    "        \n",
    "#         for intent in data['intents']:\n",
    "#             if intent['tag'] == results[0]:\n",
    "#                 responses = results[0], inp\n",
    "\n",
    "#         print(responses)\n",
    "        \n",
    "#     except:\n",
    "#         print(\"Don't understand your query please use a different term\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)\n",
    "model.save(\"kpi_identifier.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KpiIdentifier:\n",
    "    def __init__(self, data_path, model_path, json_data_path):\n",
    "        try:\n",
    "            with open(data_path, 'rb') as file:\n",
    "                self.words, self.classes, self.documents = pickle.load(file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise FileNotFoundError(f\"{data_path} doesn't exist\")\n",
    "            \n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(model_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise FileNotFoundError(f\"{model_path} doesn't exist\")\n",
    "            \n",
    "        try:\n",
    "            with open(json_data_path, \"rb\") as file:\n",
    "                self.data = json.load(file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise FileNotFoundError(f\"{json_data_path} doesn't exist\")\n",
    "           \n",
    "    @property\n",
    "    def ignore_words(self):\n",
    "        return [\"'s\"] + [s for s in string.punctuation]\n",
    "    \n",
    "    def clean_up_sentence(self, sentence):\n",
    "        s_words = nltk.word_tokenize(sentence)\n",
    "        s_words = [stemmer.stem(w.lower()) for w in s_words if w not in self.ignore_words]\n",
    "\n",
    "        return s_words\n",
    "\n",
    "    def bow(self, sentence, words, show_details=True):\n",
    "        s_words = self.clean_up_sentence(sentence)\n",
    "\n",
    "        bag = [0 for _ in range(len(words))]\n",
    "\n",
    "        for s in s_words:\n",
    "            for i, w in enumerate(words):\n",
    "                if w == s:\n",
    "                    bag[i] = 1\n",
    "\n",
    "                    if show_details:\n",
    "                        print(f\"found in bag: {s}\")\n",
    "\n",
    "        return np.array(bag)\n",
    "\n",
    "    def classify_local(self, sentence):\n",
    "        ERROR_THRESHOLD = 0.60\n",
    "\n",
    "        input_data = pd.DataFrame([self.bow(sentence, self.words, show_details=False)], dtype=float, index=['input'])\n",
    "        input_data = tf.cast(input_data.values.reshape(-1, 1, input_data.shape[1]), tf.float32)\n",
    "\n",
    "        results = self.model.predict(input_data)[0]\n",
    "\n",
    "        #filter out prediction below a threshold, and provide intent index\n",
    "        results = [[i, r] for i, r in enumerate(results) if r > ERROR_THRESHOLD]\n",
    "\n",
    "        # sort by strength of probability\n",
    "        results.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "        return_list = []\n",
    "        for r in results:\n",
    "            return_list.append((self.classes[r[0]], str(r[1])))\n",
    "                \n",
    "        print(return_list)\n",
    "        return return_list\n",
    "\n",
    "    def run(self, text):\n",
    "        try:\n",
    "            results = self.classify_local(text)[0]\n",
    "            \n",
    "            for intent in self.data[\"intents\"]:\n",
    "                if intent[\"tag\"] == results[0]: \n",
    "                    for query in text.split():\n",
    "                        for val in intent[\"validate\"]:\n",
    "                            if stemmer.stem(nltk.word_tokenize(query)[0]) == stemmer.stem(val): return results[0], text\n",
    "                            elif results[0] == \"definition\" and re.search(r\"\"\"(?:is\\s)\\w{3,}\"\"\", text): return results[0], text\n",
    "                    return None\n",
    "                \n",
    "        except IndexError:\n",
    "            return None\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    \n",
    "# identifier = KpiIdentifier(data_path=\"data.pickle\", model_path=\"kpi_identifier.hdf5\", json_data_path=\"kpi_identifier.json\")\n",
    "# identifier.run(text=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Text:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('greetings', '0.99934465')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('greetings', 'hello')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how are we doing on refung\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how are we doing on refund\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('refund', '0.99999714')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('refund', 'how are we doing on refund')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  invoice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.9997174')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'invoice')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how are my paid invoice today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.9999871')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'how are my paid invoice today?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how are we doing on invoice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.99999607')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'how are we doing on invoice')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how is my invoice?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.9999819')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'how is my invoice?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how is my invoices?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.9999819')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'how is my invoices?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how are we doing on invoices?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.99999607')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'how are we doing on invoices?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Text:  how are we doing on invoice?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoice', '0.99999607')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('invoice', 'how are we doing on invoice?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "identifier = KpiIdentifier(data_path=\"data.pickle\", model_path=\"kpi_identifier.hdf5\", json_data_path=\"kpi_identifier.json\")\n",
    "text = input(\"Enter Text: \")\n",
    "\n",
    "while True:\n",
    "    if text in [\"quit\", \"exit\", \"stop\", \"q\", \"s\", \"e\"]:\n",
    "        break\n",
    "    \n",
    "    display(identifier.run(text=text))\n",
    "    text = input(\"\\nEnter Text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
